{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f66a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import LLMUtils\n",
    "import Datasets\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6d2f6-a896-4e10-bd36-da7ac5d4c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACE_TOKEN = \"\" # Needed for restricted LLMs with EULAs (Llama...)\n",
    "GEMINI_API_KEY = \"\" # Needed to interact with Google's LLM API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c3d794-febb-45b3-b68c-be17d2656690",
   "metadata": {},
   "source": [
    "# Run the tests\n",
    "Note that, depending on the model, this test may run for up to 12 hours. The progress and remaining time will be logged to `progress.log`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4bfa2-f337-4a9d-b361-f4d15f0d57ac",
   "metadata": {},
   "source": [
    "## Local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e776c6d-f676-485a-adf2-143e85d7186a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Datasets.WebNLGDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039d9603-615d-4e26-8754-229b66559cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts the LLM and saves all results to a file\n",
    "def get_and_save_results(n_samples, LLM, dataset, avoid_explanations):\n",
    "    generated_triples = []\n",
    "\n",
    "    invalid_responses = 0\n",
    "\n",
    "    for i, (text, triples) in (pbar := tqdm(enumerate(dataset.test_samples), file=open(\"progress.log\", \"w\"), total=len(dataset.test_samples))):\n",
    "        pbar.set_description(f\"\\r{n_samples} test: Obtained sample {i+1}\\\\{len(dataset.test_samples)} (invalid responses: {invalid_responses})\")\n",
    "\n",
    "        system_prompt, user_prompt = dataset.get_prompts(None, text, n_samples, avoid_explanations)\n",
    "        triples = LLM.get_triples(system_prompt, user_prompt)\n",
    "\n",
    "        # All samples contain triples. Whether this was due to detecting \n",
    "        # an error or the model believing there are no relations to extract,\n",
    "        # it will be treated as an invalid response, with its subsequent\n",
    "        # penalization during evaluation\n",
    "        if len(triples) == 0: \n",
    "            invalid_responses += 1\n",
    "\n",
    "        generated_triples.append(triples)\n",
    "\n",
    "    with open(f'results_llm_testing/results_{LLM.get_human_readable_model_name()}_webnlg_{n_samples}_samples.txt', 'w') as file:\n",
    "        for (text, ground_truth_triples), gen_triples in zip(dataset.test_samples, generated_triples):\n",
    "            file.write(f'Sample: {text}\\n')\n",
    "            file.write(f'Ground truth: {ground_truth_triples}\\n')\n",
    "            file.write(f'Generated triples: {gen_triples}\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745f6a5-5f6e-48b4-8a3e-35410522663e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for llm_name in LLMUtils.LLM.models_for_testing:\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    LLM = LLMUtils.LLM(llm_name, hf_token=HUGGINGFACE_TOKEN)\n",
    "\n",
    "    avoid_explanations = True\n",
    "\n",
    "    get_and_save_results(5, LLM, dataset, avoid_explanations)\n",
    "    get_and_save_results(8, LLM, dataset, avoid_explanations)\n",
    "    get_and_save_results(16, LLM, dataset, avoid_explanations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3b089-1cc3-4e98-be0e-e455374cb6ee",
   "metadata": {},
   "source": [
    "# Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67055910-971f-4bb6-bb90-1bd462b83cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_and_save_results_gemini(n_samples, dataset, avoid_explanations):\n",
    "    client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "    if os.path.exists(f\"gemini_results_{n_samples}.json\"):\n",
    "        with open(f\"gemini_results_{n_samples}.json\") as f:\n",
    "            gemini_results = json.load(f)\n",
    "    else:\n",
    "        gemini_results = dict()\n",
    "\n",
    "    requests_made = 0  # Counter for requests made in the current minute\n",
    "    start_time = time.time()  # Track the start of the 1-minute window\n",
    "\n",
    "    for i, (text, _) in (pbar := tqdm(enumerate(dataset.test_samples), total=len(dataset.test_samples))):\n",
    "        pbar.set_description(f\"\\r{n_samples} test: Obtained sample {i+1}\\\\{len(dataset.test_samples)}\")\n",
    "\n",
    "        if text in gemini_results:\n",
    "            continue\n",
    "\n",
    "        # Check if we've hit the 15 RPM limit of the API\n",
    "        if requests_made >= 15:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time < 60:\n",
    "                time.sleep(60 - elapsed_time)  # Wait until the 1-minute window resets (+15 extra seconds)\n",
    "            requests_made = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "        system_prompt, user_prompt = dataset.get_prompts(None, text, n_samples, avoid_explanations)\n",
    "        while True:\n",
    "            try:\n",
    "                raw_response = client.models.generate_content(\n",
    "                    model=\"gemini-2.0-flash\",\n",
    "                    config=types.GenerateContentConfig(system_instruction=system_prompt),\n",
    "                    contents=[user_prompt]\n",
    "                )\n",
    "\n",
    "                requests_made += 1\n",
    "            \n",
    "                break  \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                requests_made = 0\n",
    "                time.sleep(60) # Wait a full minute, it may be a hidden limit\n",
    "\n",
    "        LLM = LLMUtils.LLM(None)\n",
    "        generated_triples = LLM.get_triples_from_existing_response(raw_response.text)\n",
    "\n",
    "        gemini_results[text] = generated_triples\n",
    "        with open(f\"gemini_results_{n_samples}.json\", \"w\") as f: \n",
    "            json.dump(gemini_results, f)\n",
    "\n",
    "    with open(f'results_llm_testing/results_Gemini_2.0_Flash_webnlg_{n_samples}_samples.txt', 'w') as file:\n",
    "        for text, ground_truth_triples in dataset.test_samples:\n",
    "            file.write(f'Sample: {text}\\n')\n",
    "            file.write(f'Ground truth: {ground_truth_triples}\\n')\n",
    "            file.write(f'Generated triples: {gemini_results[text]}\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b714d03-77ac-4f2c-ae0f-108f6b8e7ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_and_save_results_gemini(5, dataset, True)\n",
    "get_and_save_results_gemini(8, dataset, True)\n",
    "get_and_save_results_gemini(16, dataset, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [jrcACLJEOLAB]",
   "language": "python",
   "name": "conda-env-jrcACLJEOLAB-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
