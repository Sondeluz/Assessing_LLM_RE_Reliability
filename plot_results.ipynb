{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f3bf7e-d4a0-4056-ad08-a0640f142c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import matplotlib as mpl\n",
    "import seaborn.objects as so\n",
    "from enum import Enum\n",
    "import Datasets\n",
    "from seaborn import axes_style\n",
    "from scipy.stats import linregress\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97624a05-148d-4f91-98fa-7d0fb995118b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# WebNLG plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592aef84-7c0f-4448-802d-e098d391ab24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_webnlg = pd.read_csv('results_llm_testing/results_llms.csv')\n",
    "scores_webnlg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5b2ff-1f01-4455-b6fa-27509601d248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_webnlg_results(metric, metric_name, metric_name_axis=None):\n",
    "    if metric_name_axis is None:\n",
    "        metric_name_axis = metric_name\n",
    "    \n",
    "    scores_webnlg = pd.read_csv('results_llm_testing/results_llms.csv')\n",
    "    scores_webnlg[\"Examples provided\"] = scores_webnlg[\"Examples provided\"].astype(str)\n",
    "    scores_webnlg[\"In-Context examples\"] = scores_webnlg[\"Examples provided\"]\n",
    "    scores_webnlg[\"Invalid outputs\"] = scores_webnlg[\"Invalid outputs\"] / 7253 # number of test samples in WebNLG\n",
    "\n",
    "    scores_webnlg['LLM'] = scores_webnlg['LLM'].replace(\"Gemma-2 (2B)\", \"Gemma-2\\n(2B)\")\n",
    "    scores_webnlg['LLM'] = scores_webnlg['LLM'].replace(\"Llama-3.2 (3B)\", \"Llama-3.2\\n(3B)\")\n",
    "    scores_webnlg['LLM'] = scores_webnlg['LLM'].replace(\"Phi-3.5 (3.8B)\", \"Phi-3.5\\n(3.8B)\")\n",
    "    scores_webnlg['LLM'] = scores_webnlg['LLM'].replace(\"Llama-3.1 (8B)\", \"Llama-3.1\\n(8B)\")\n",
    "    scores_webnlg['LLM'] = scores_webnlg['LLM'].replace(\"Gemma-2 (9B)\", \"Gemma-2\\n(9B)\")\n",
    "    scores_webnlg['LLM'] = scores_webnlg['LLM'].replace(\"Gemini\", \"Gemini\\n2.0 Flash\")\n",
    "\n",
    "    plot = (\n",
    "        so.Plot(scores_webnlg, x=\"LLM\", y=metric, color=\"In-Context examples\") # doesn't work at all\n",
    "            .add(so.Bar(), so.Dodge(empty=\"drop\"))\n",
    "\n",
    "            .scale(color=\"Paired\", y=so.Continuous().tick(every=0.1))\n",
    "            .layout(size=(14, 12), engine=\"tight\")\n",
    "            .limit()\n",
    "            .label(x=\"Model\", y=metric_name_axis, title=f\"{metric_name} for the WebNLG Evaluation\")\n",
    "    )\n",
    "\n",
    "    plot = plot.theme({\n",
    "        \"xtick.labelsize\": 32,  \n",
    "        \"ytick.labelsize\": 32,  \n",
    "        \"axes.labelsize\": 32,   \n",
    "        \"axes.titlesize\": 34,   \n",
    "        \"legend.title_fontsize\": 26,  \n",
    "        \"legend.fontsize\": 26,  \n",
    "        \"axes.titlepad\": 25, \n",
    "        \"axes.labelpad\": 10, \n",
    "        **axes_style(\"ticks\"), # White background, ticks on axes, no grid\n",
    "        \"axes.grid\": True, # Add the grid\n",
    "    })\n",
    "\n",
    "    # Hack to be able to move the legend, seaborn objects doesn't allow this properly yet\n",
    "    f = mpl.figure.Figure(figsize=(14, 12))\n",
    "    res = plot.on(f).plot()\n",
    "    f.legends[0].set_bbox_to_anchor((0.65, 0.8))\n",
    "    f.axes[0].set_ylim(0, 1)\n",
    "    f.axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    f.canvas.flush_events()\n",
    "    f.savefig(f\"webnlg_{metric_name.lower().replace(' ', '_')}.png\",  bbox_inches='tight')\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f54a881-d5dc-4e32-b662-3262ac3f5045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_webnlg_results(\"Precision (strict)\", \"Precision (Strict) results\")\n",
    "plot_webnlg_results(\"Precision (relaxed)\", \"Precision (Relaxed) results\")\n",
    "plot_webnlg_results(\"Avg. Rouge-2 (space separators)\", \"ROUGE-2 results\")\n",
    "plot_webnlg_results(\"Invalid outputs\", \"Error Rate\", metric_name_axis=\"Error Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00962a94-ec3b-46f1-978c-1444425f8977",
   "metadata": {},
   "source": [
    "# DocRED and Biomedical Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7692c3b4-e7b9-4c19-b394-396d07abbc90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Possible prompt strategies to do\n",
    "# PREVIOUS_SENTENCES: Split the text into chunks of n sentences,\n",
    "#                     with an overlap of m sentences which will\n",
    "#                     act as the context. n and m can be any\n",
    "#                     value (e.g. n=1, m=0 traverses it sentence\n",
    "#                     by sentence with no context). The iterator\n",
    "#                     will adjust the overlap in the first sentence(s)\n",
    "#                     where there may not be enough preceding ones\n",
    "#\n",
    "# SECTION_CONTENTS: Generate triples for the whole section at once\n",
    "PromptStrategy = Enum('PromptStrategy', ['PREVIOUS_SENTENCES', 'SECTION_CONTENTS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d116b803-5b01-4582-a801-c7b1dbfb63fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## General barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245fff1-9874-4dd1-9af8-1f9f44d89249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_amount_of_triples_generated_tests_model_comparison(csv_path_model_1,\n",
    "                                                            csv_path_model_2,\n",
    "                                                            csv_path_model_3,\n",
    "                                                            model_name_1,\n",
    "                                                            model_name_2,\n",
    "                                                            model_name_3,\n",
    "                                                            type_of_text):\n",
    "    df_1 = pd.read_csv(csv_path_model_1).sort_values(['sentences_per_prompt', 'overlap'])\n",
    "    df_1[\"Model\"] = model_name_1\n",
    "    df_2 = pd.read_csv(csv_path_model_2).sort_values(['sentences_per_prompt', 'overlap'])\n",
    "    df_2[\"Model\"] = model_name_2\n",
    "    df_3 = pd.read_csv(csv_path_model_3).sort_values(['sentences_per_prompt', 'overlap'])\n",
    "    df_3[\"Model\"] = model_name_3\n",
    "\n",
    "    df_1_contents = df_1[(df_1[\"prompt_strategy\"] == str(PromptStrategy.SECTION_CONTENTS)) & (df_1[\"sentences_per_prompt\"] == 0.0)]\n",
    "    df_2_contents = df_2[(df_2[\"prompt_strategy\"] == str(PromptStrategy.SECTION_CONTENTS)) & (df_2[\"sentences_per_prompt\"] == 0.0)]\n",
    "    df_3_contents = df_3[(df_3[\"prompt_strategy\"] == str(PromptStrategy.SECTION_CONTENTS)) & (df_3[\"sentences_per_prompt\"] == 0.0)]\n",
    "\n",
    "    df_1_sentences = df_1[df_1[\"prompt_strategy\"] == str(PromptStrategy.PREVIOUS_SENTENCES)]\n",
    "    df_2_sentences = df_2[df_2[\"prompt_strategy\"] == str(PromptStrategy.PREVIOUS_SENTENCES)]\n",
    "    df_3_sentences = df_3[df_3[\"prompt_strategy\"] == str(PromptStrategy.PREVIOUS_SENTENCES)]\n",
    "\n",
    "    combined_df_contents = pd.concat([df_1_contents, df_2_contents, df_3_contents], ignore_index=True)\n",
    "\n",
    "    avg_model_1 = df_1_sentences.groupby(['Model'])['total_triples'].mean().reset_index().rename(columns={\"total_triples\": \"avg\"})\n",
    "    avg_model_2 = df_2_sentences.groupby(['Model'])['total_triples'].mean().reset_index().rename(columns={\"total_triples\": \"avg\"})\n",
    "    avg_model_3 = df_3_sentences.groupby(['Model'])['total_triples'].mean().reset_index().rename(columns={\"total_triples\": \"avg\"})\n",
    "\n",
    "    plot = (\n",
    "        so.Plot(combined_df_contents, x=\"Model\", y=\"total_triples\")\n",
    "            .add(so.Bar(alpha=0.9, width=1.6), so.Dodge(empty=\"drop\"), color=\"Model\", legend=True, label=\"Paragraph\")\n",
    "\n",
    "            .add(so.Bar(alpha=0.25, edgestyle='--', width=0.5300),\n",
    "                 so.Dodge(empty=\"drop\"), data=avg_model_1, x=\"Model\", y=\"avg\", color=\"Model\", legend=True, label=\"Sliding Window\")\n",
    "            .add(so.Bar(alpha=0.25, edgestyle='--', width=0.5300),\n",
    "                 so.Dodge(empty=\"drop\"), data=avg_model_2, x=\"Model\", y=\"avg\", color=\"Model\", legend=True)\n",
    "            .add(so.Bar(alpha=0.25, edgestyle='--', width=0.5300),\n",
    "                 so.Dodge(empty=\"drop\"), data=avg_model_3, x=\"Model\", y=\"avg\", color=\"Model\", legend=True)\n",
    "\n",
    "            .add(so.Dot(pointsize=10, alpha=1), data=avg_model_1, x=\"Model\", y=\"avg\", color=\"Model\", legend=False)\n",
    "            .add(so.Dot(pointsize=10, alpha=1), data=avg_model_2, x=\"Model\", y=\"avg\", color=\"Model\", legend=False)\n",
    "            .add(so.Dot(pointsize=10, alpha=1), data=avg_model_3, x=\"Model\", y=\"avg\", color=\"Model\", legend=False)\n",
    "\n",
    "            .add(so.Range(linewidth=8, alpha=0.45), so.Est(errorbar=\"sd\"),\n",
    "                 x=\"Model\", y=\"total_triples\", data=df_1_sentences[[\"Model\", \"total_triples\"]], color=\"Model\", legend=False)\n",
    "            .add(so.Range(linewidth=8, alpha=0.45), so.Est(errorbar=\"sd\"), \n",
    "                 x=\"Model\", y=\"total_triples\", data=df_2_sentences[[\"Model\", \"total_triples\"]], color=\"Model\", legend=False)\n",
    "            .add(so.Range(linewidth=8, alpha=0.45), so.Est(errorbar=\"sd\"), \n",
    "                 x=\"Model\", y=\"total_triples\", data=df_3_sentences[[\"Model\", \"total_triples\"]], color=\"Model\", legend=False)\n",
    "\n",
    "            .scale(color=\"Paired\", x=so.Nominal(), y=so.Continuous().tick(every=5))\n",
    "            .layout(size=(16, 12), engine=\"tight\")\n",
    "            .limit()\n",
    "            .label(x=\"Model\", y=\"Avg. Generated Triples\", legend=\"Strategy\", title=f\"Effect Of the Choice of Model on the Avg. Generated Triples\\n({type_of_text})\")\n",
    "    )\n",
    "\n",
    "    plot = plot.theme({\n",
    "        \"xtick.labelsize\": 32,\n",
    "        \"ytick.labelsize\": 32,\n",
    "        \"axes.labelsize\": 32,\n",
    "        \"axes.titlesize\": 34,\n",
    "        \"legend.title_fontsize\": 26,\n",
    "        \"legend.fontsize\": 26,\n",
    "        \"axes.titlepad\": 25,\n",
    "        \"axes.labelpad\": 10,\n",
    "        **axes_style(\"ticks\"), # White background, ticks on axes, no grid\n",
    "        \"axes.grid\": True, # Add the grid\n",
    "    })\n",
    "\n",
    "    # Hack to be able to move the legend, seaborn objects doesn't allow this properly yet\n",
    "    f = mpl.figure.Figure(figsize=(14, 12))\n",
    "    res = plot.on(f).plot()\n",
    "    f.legends[0].set_bbox_to_anchor((0.1, 0.71))\n",
    "\n",
    "    f.canvas.flush_events()\n",
    "    f.savefig(f\"amount_of_triples_test_models_comparison_{type_of_text.lower().replace(' ', '_')}.png\",  bbox_inches='tight')\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe081b4-d8b8-4ead-bc41-c345b6c0975b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_amount_of_triples_generated_tests_model_comparison(\"results_paper_triples/biomedical_papers/phi_3b/paper_triples_results_clean.csv\", \n",
    "                                                        \"results_paper_triples/biomedical_papers/llama_8b/paper_triples_results_clean.csv\",\n",
    "                                                        \"results_paper_triples/biomedical_papers/gemma_9b/paper_triples_results_clean.csv\",\n",
    "\n",
    "                                                        \"Phi-3.5 (3.8B)\",\n",
    "                                                        \"Llama-3.1 (8B)\",\n",
    "                                                        \"Gemma-2 (9B)\",\n",
    "\n",
    "                                                        \"Biomedical Texts\")\n",
    "\n",
    "plot_amount_of_triples_generated_tests_model_comparison(\"results_paper_triples/docred/phi_3b/paper_triples_results_clean.csv\", \n",
    "                                                        \"results_paper_triples/docred/llama_8b/paper_triples_results_clean.csv\",\n",
    "                                                        \"results_paper_triples/docred/gemma_9b/paper_triples_results_clean.csv\",\n",
    "\n",
    "                                                        \"Phi-3.5 (3.8B)\",\n",
    "                                                        \"Llama-3.1 (8B)\",\n",
    "                                                        \"Gemma-2 (9B)\",\n",
    "\n",
    "                                                        \"DocRED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e74ecd-b941-4938-91e1-6e76607d70a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Per-sentences, number of triples barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe8799-36ff-4cfb-b121-21c27e8ac408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_avg_triples_fit(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.sort_values(by=['sentences_per_prompt', 'overlap'])\n",
    "    df = df[df[\"sentences_per_prompt\"] > 0]  # Don't show SECTION_SENTENCES\n",
    "    df['overlap'] = df['overlap'].astype(int)\n",
    "\n",
    "    # Calculate average and standard deviation per group\n",
    "    avg = df.groupby(['sentences_per_prompt'])['total_triples'].mean().reset_index()\n",
    "    stddev = df.groupby(['sentences_per_prompt'])['total_triples'].std().reset_index()\n",
    "\n",
    "    avg = avg.rename(columns={\"total_triples\": \"avg\"})\n",
    "    stddev = stddev.rename(columns={\"total_triples\": \"std\"})\n",
    "\n",
    "\n",
    "    merged_df = pd.merge(avg, stddev, on='sentences_per_prompt')\n",
    "\n",
    "    x = merged_df['sentences_per_prompt']\n",
    "    y = merged_df['avg']\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "\n",
    "\n",
    "    return slope, p_value, slope * x + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2cb520-7432-4d6a-b729-29186c10b889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_amount_of_triples_generated_tests_bars_stddev(csv_path, model_name, type_of_text):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.sort_values(by=['sentences_per_prompt', 'overlap'])\n",
    "    df = df[df[\"sentences_per_prompt\"] > 0]  # Don't show SECTION_SENTENCES\n",
    "    df['overlap'] = df['overlap'].astype(int)\n",
    "\n",
    "    # Calculate per-group average\n",
    "    avg = df.groupby(['sentences_per_prompt'])['total_triples'].mean().reset_index()\n",
    "    avg = avg.rename(columns={\"total_triples\": \"avg\"})\n",
    "\n",
    "    df['Overlap'] = df['overlap'].apply(lambda x: f\"{x} Ctx. Sentences\" if x != 0 else \"No Context\")\n",
    "\n",
    "    slope, p_value, regression_fit = get_avg_triples_fit(csv_path)\n",
    "\n",
    "    fit_df = pd.DataFrame({\n",
    "        \"sentences_per_prompt\": avg[\"sentences_per_prompt\"],\n",
    "        \"fitted\": regression_fit\n",
    "    })\n",
    "\n",
    "    df = df.rename(columns={\"Overlap\": \"Overlap ($m$)\"})\n",
    "\n",
    "    plot = (\n",
    "        so.Plot(df, x=\"sentences_per_prompt\", y=\"total_triples\")\n",
    "\n",
    "            .add(so.Line(linestyle='--', color='dimgrey'), data=fit_df, x=\"sentences_per_prompt\", y=\"fitted\")  # Regression fit\n",
    "\n",
    "            .add(so.Bar(), so.Dodge(empty=\"drop\"), color=\"Overlap ($m$)\", legend=True)\n",
    "\n",
    "            .add(so.Dot(pointsize=5, color=\"black\"), data=avg, x=\"sentences_per_prompt\", y=\"avg\")\n",
    "            .add(so.Range(linewidth=2, color=\"black\"), so.Est(errorbar=\"sd\"), data=df[[\"sentences_per_prompt\", \"total_triples\"]])\n",
    "\n",
    "            .scale(color=\"Paired\", x=so.Continuous().tick(every=1), y=so.Continuous().tick(every=10))\n",
    "            .layout(size=(16, 18), engine=\"tight\")\n",
    "            .limit()\n",
    "            .label(x=\"Sentences per Prompt ($k$)\", y=\"Avg. Generated Triples\", legend=\"Overlap ($m$)\", \n",
    "                   title=f\"Sliding Window Strategy Effect on the Avg. Generated Triples\\n({model_name}, {type_of_text}) ($m$={slope:.3f}, $p$={p_value:.1e})\")\n",
    "    )\n",
    "\n",
    "    plot = plot.theme({\n",
    "        \"xtick.labelsize\": 32,\n",
    "        \"ytick.labelsize\": 32,\n",
    "        \"axes.labelsize\": 32,\n",
    "        \"axes.titlesize\": 34,\n",
    "        \"legend.title_fontsize\": 26,\n",
    "        \"legend.fontsize\": 26,\n",
    "        \"axes.titlepad\": 25,\n",
    "        \"axes.labelpad\": 10,\n",
    "        **axes_style(\"ticks\"), # White background, ticks on axes, no grid\n",
    "        \"axes.grid\": True, # Add the grid\n",
    "    })\n",
    "\n",
    "    # Hack to be able to move the legend, seaborn objects doesn't allow this properly yet\n",
    "    f = mpl.figure.Figure(figsize=(14, 12))\n",
    "    res = plot.on(f).plot()\n",
    "    f.legends[0].set_bbox_to_anchor((0.7, 0.67))\n",
    "    f.axes[0].set_ylim(0, 100)\n",
    "\n",
    "    f.canvas.flush_events()\n",
    "    f.savefig(f\"amount_of_triples_test_{model_name.lower().replace(' ', '_')}_{type_of_text.lower().replace(' ', '_')}_bars.png\",  bbox_inches='tight')\n",
    "    return f\n",
    "\n",
    "plot_amount_of_triples_generated_tests_bars_stddev(\"results_paper_triples/biomedical_papers/gemma_9b/paper_triples_results_clean.csv\", \"Gemma 9B\", \"Biomed. Papers\")\n",
    "plot_amount_of_triples_generated_tests_bars_stddev(\"results_paper_triples/docred/gemma_9b/paper_triples_results_clean.csv\", \"Gemma 9B\", \"DocRED\")\n",
    "\n",
    "plot_amount_of_triples_generated_tests_bars_stddev(\"results_paper_triples/docred/llama_8b/paper_triples_results_clean.csv\", \"Llama 8B\", \"DocRED\")\n",
    "plot_amount_of_triples_generated_tests_bars_stddev(\"results_paper_triples/biomedical_papers/llama_8b/paper_triples_results_clean.csv\", \"Llama 8B\", \"Biomed. Papers\")\n",
    "\n",
    "plot_amount_of_triples_generated_tests_bars_stddev(\"results_paper_triples/biomedical_papers/phi_3b/paper_triples_results_clean.csv\", \"Phi 3B\", \"Biomed. Papers\")\n",
    "plot_amount_of_triples_generated_tests_bars_stddev(\"results_paper_triples/docred/phi_3b/paper_triples_results_clean.csv\", \"Phi 3B\", \"DocRED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd51ac-5d45-40ae-a71b-6848e8f912f2",
   "metadata": {},
   "source": [
    "## Per-sentences, error rate barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8569c217-f9c5-42d4-a40a-82c0dde2e150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_error_rate_fit(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.sort_values(by=['sentences_per_prompt', 'overlap'])\n",
    "    df = df[df[\"sentences_per_prompt\"] > 0]  # Don't show SECTION_SENTENCES\n",
    "    df['overlap'] = df['overlap'].astype(int)\n",
    "\n",
    "    # Show the ratio over the total\n",
    "    df['bad_triples'] = df['bad_triples'] / df['total_triples']\n",
    "\n",
    "    # Calculate average and standard deviation per group\n",
    "    avg = df.groupby(['sentences_per_prompt'])['bad_triples'].mean().reset_index()\n",
    "    stddev = df.groupby(['sentences_per_prompt'])['bad_triples'].std().reset_index()\n",
    "\n",
    "    avg = avg.rename(columns={\"bad_triples\": \"avg\"})\n",
    "    stddev = stddev.rename(columns={\"bad_triples\": \"std\"})\n",
    "\n",
    "\n",
    "    merged_df = pd.merge(avg, stddev, on='sentences_per_prompt')\n",
    "\n",
    "    x = merged_df['sentences_per_prompt']\n",
    "    y = merged_df['avg']\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "\n",
    "    return slope, p_value, slope * x + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e1f2b-682f-4b40-9279-6f584eac7b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_error_rates_bars_stddev(csv_path, model_name, type_of_text):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.sort_values(by=['sentences_per_prompt', 'overlap'])\n",
    "    df = df[df[\"sentences_per_prompt\"] > 0]  # Don't show SECTION_SENTENCES\n",
    "    df['overlap'] = df['overlap'].astype(int)\n",
    "\n",
    "    # Show the ratio over the total\n",
    "    df['bad_triples'] = df['bad_triples'] / df['total_triples']\n",
    "\n",
    "    # Calculate average and standard deviation per group\n",
    "    avg = df.groupby(['sentences_per_prompt'])['bad_triples'].mean().reset_index()\n",
    "    avg = avg.rename(columns={\"bad_triples\": \"avg\"})\n",
    "\n",
    "    df['Overlap'] = df['overlap'].apply(lambda x: f\"{x} Ctx. Sentences\" if x != 0 else \"No Context\")\n",
    "\n",
    "    global_avg = df.assign(sentences_per_prompt=5.5)[[\"sentences_per_prompt\", \"bad_triples\"]].mean().to_frame().T\n",
    "\n",
    "    slope, p_value, regression_fit = get_error_rate_fit(csv_path)\n",
    "\n",
    "    fit_df = pd.DataFrame({\n",
    "        \"sentences_per_prompt\": avg[\"sentences_per_prompt\"],\n",
    "        \"fitted\": regression_fit\n",
    "    })\n",
    "\n",
    "    df = df.rename(columns={\"Overlap\": \"Overlap ($m$)\"})\n",
    "\n",
    "    plot = (\n",
    "        so.Plot(df, x=\"sentences_per_prompt\", y=\"bad_triples\")\n",
    "            .add(so.Line(linestyle='--', color='dimgrey'), data=fit_df, x=\"sentences_per_prompt\", y=\"fitted\")  # Regression fit\n",
    "\n",
    "            .add(so.Bar(), so.Dodge(empty=\"drop\"), color=\"Overlap ($m$)\", legend=True)\n",
    "\n",
    "            .add(so.Dot(pointsize=5, color=\"black\"), data=avg, x=\"sentences_per_prompt\", y=\"avg\")\n",
    "            .add(so.Range(linewidth=2, color=\"black\"), so.Est(errorbar=\"sd\"), data=df[[\"sentences_per_prompt\", \"bad_triples\"]])\n",
    "\n",
    "            .scale(color=\"Paired\", x=so.Continuous().tick(every=1), y=so.Continuous().tick(every=0.002))\n",
    "            .layout(size=(16, 18), engine=\"tight\")\n",
    "            .limit()\n",
    "            .label(x=\"Sentences per Prompt ($k$)\", y=\"Avg. Incorrect Triples (Ratio Over Total)\", legend=\"Overlap ($m$)\", \n",
    "                   title=f\"Sliding Window Strategy Effect on the Error Rate\\n({model_name}, {type_of_text}) ($m$={slope:.3f}, $p$={p_value:.1e})\")\n",
    "    )\n",
    "\n",
    "    plot = plot.theme({\n",
    "        \"xtick.labelsize\": 32,\n",
    "        \"ytick.labelsize\": 32,\n",
    "        \"axes.labelsize\": 32,\n",
    "        \"axes.titlesize\": 34,\n",
    "        \"legend.title_fontsize\": 26,\n",
    "        \"legend.fontsize\": 26,\n",
    "        \"axes.titlepad\": 25,\n",
    "        \"axes.labelpad\": 10,\n",
    "        **axes_style(\"ticks\"), # White background, ticks on axes, no grid\n",
    "        \"axes.grid\": True, # Add the grid\n",
    "    })\n",
    "\n",
    "    # Hack to be able to move the legend, seaborn objects doesn't allow this properly yet\n",
    "    f = mpl.figure.Figure(figsize=(14, 12))\n",
    "    res = plot.on(f).plot()\n",
    "    f.legends[0].set_bbox_to_anchor((0.14, 0.66))\n",
    "    f.axes[0].set_ylim(0, 0.03)\n",
    "\n",
    "    f.canvas.flush_events()\n",
    "    f.savefig(f\"error_rates_test_{model_name.lower().replace(' ', '_')}_{type_of_text.lower().replace(' ', '_')}_bars.png\",  bbox_inches='tight')\n",
    "    return f\n",
    "\n",
    "\n",
    "plot_error_rates_bars_stddev(\"results_paper_triples/biomedical_papers/gemma_9b/paper_triples_results_clean.csv\", \"Gemma 9B\", \"Biomed. Papers\")\n",
    "plot_error_rates_bars_stddev(\"results_paper_triples/docred/gemma_9b/paper_triples_results_clean.csv\", \"Gemma 9B\", \"DocRED\")\n",
    "\n",
    "plot_error_rates_bars_stddev(\"results_paper_triples/docred/llama_8b/paper_triples_results_clean.csv\", \"Llama 8B\", \"DocRED\")\n",
    "plot_error_rates_bars_stddev(\"results_paper_triples/biomedical_papers/llama_8b/paper_triples_results_clean.csv\", \"Llama 8B\", \"Biomed. Papers\")\n",
    "\n",
    "plot_error_rates_bars_stddev(\"results_paper_triples/biomedical_papers/phi_3b/paper_triples_results_clean.csv\", \"Phi 3B\", \"Biomed. Papers\")\n",
    "plot_error_rates_bars_stddev(\"results_paper_triples/docred/phi_3b/paper_triples_results_clean.csv\", \"Phi 3B\", \"DocRED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda_py310]",
   "language": "python",
   "name": "conda-env-conda_py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
